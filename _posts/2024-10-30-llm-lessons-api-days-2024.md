---
title: "Lessons from the Trenches in a LLM Frontier: An Engineer's Perspective - Apidays Australia 2024"
date: 2025-05-18 22:06
comments: true
header:
  teaser: /assets/images/apidays/api-days-australia-2024-teaser.png
categories: [Conference, LLM, AI, Software Engineering, Generative AI]
tags: [apidays, LLM, AI, public speaking, engineering, MLOps, responsible AI]
toc: true
toc_label: "Content"
toc_sticky: true
---

I, along with my colleagues Jason Goodsell and Juan Burckhardt, had the opportunity to present our key insights and learnings from the rapidly evolving world of Large Language Models (LLMs) at [Apidays Australia 2024](https://apidays.global/australia/) in October. The talk, titled "Lessons from the Trenches in a LLM Frontier: An Engineer's Perspective," shared our experiences from the front lines of developing LLM-powered solutions.

Our team has been deeply immersed in creating and integrating LLM solutions, observing firsthand the industry's intense focus and the eagerness of engineering teams to incorporate this technology into their products. This often involves developing "Copilot-like" features to augment user workflows through natural language interaction.

The drive to innovate with LLMs is immense, especially with the technology becoming more accessible beyond big tech corporations. However, this rapid adoption brings challenges. While the potential is huge, the risks of failed integrations can be significant, leading to increased caution. Furthermore, the rush to build can sometimes mean critical aspects for robust, production-ready systems are overlooked. Many online guides that promise quick expertise often don't cover these advanced but crucial topics.

In our talk, we aimed to provide an engineer's viewpoint, developed from collaborating within a multi-disciplinary team that includes data scientists. We focused on practical considerations that teams might want to adopt, especially concerning content safety, compliance, preventing misuse, ensuring accuracy, and maintaining security – all vital for successful and responsible LLM deployment.

![Apidays Australia 2024 - LLM Lessons](/assets/images/apidays/api-days-2024-speaking.JPG)

The video of our presentation is available on YouTube, and the slides can be found on Speaker Deck:

* **Video of the talk:** [Apidays Australia 2024 - Lessons from the Trenches in a LLM Frontier: Engineer's Perspective.](https://www.youtube.com/watch?v=LFBiwKBniGE)
* **Slides:** [Lessons from the Trenches in a LLM Frontier: An Engineer's Perspective on Speaker Deck](https://speakerdeck.com/dasiths/lessons-from-the-trenches-in-a-llm-frontier-an-engineers-perspective)

The talk abstract is as follows:

> For the past year or so, our industry has been intensely focused on large language models (LLMs), with numerous engineering teams eager to integrate them into their offerings. A trending approach involves developing features like “Copilot” that augment current user interaction workflows. Often, these integrations allow users to engage with a product's features through natural language by utilizing an LLM.
>
> However, when such integrations fail, it can be an epic disaster that draws considerable attention. Consequently, companies have become more prudent about these risks, yet they also strive to keep pace with AI advancements. While big tech corporations possess the infrastructure to develop these systems, there's a notable movement towards wider access to this technology, enabling smaller teams to embark on building them without extensive knowledge or experience, potentially overlooking critical aspects in the rapid development landscape.
>
> Most online guides that promise quick expertise typically fail to account for these advanced topics. For robust production deployment, issues such as content safety, compliance, prevention of misuse, accuracy, and security are crucial.
>
> Having spent significant time developing LLM solutions with my team, we've gathered key insights from our practical experience. I intend to offer my point of view as an engineer collaborating with data scientists within a multi-disciplinary team about certain factors your teams may consider adopting.

## Recording

<iframe width="560" height="315" src="https://www.youtube.com/embed/LFBiwKBniGE?si=-8qooAwu4INPTf6Z" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Slide Deck

<iframe class="speakerdeck-iframe" frameborder="0" src="https://speakerdeck.com/player/026ea017376642c183d834b9d970010d" title="Lessons from the trenches in a LLM frontier: An Engineers Perspective" allowfullscreen="true" style="border: 0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;" data-ratio="1.7777777777777777"></iframe>

<br /><br />
If you have any thoughts or comments please leave them here. Thanks for taking the time to read this post.